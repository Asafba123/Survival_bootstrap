{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "120456f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/asaf/miniconda3/envs/dan7/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "2025-03-10 09:57:02.871202: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-10 09:57:02.937169: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-10 09:57:02.955704: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-10 09:57:03.243771: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/R/lib:/usr/lib/x86_64-linux-gnu:/usr/lib/jvm/default-java/lib/server::/home/asaf/miniconda3/envs/dan7/lib/::/home/asaf/miniconda3/envs/dan7/lib/\n",
      "2025-03-10 09:57:03.243812: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/R/lib:/usr/lib/x86_64-linux-gnu:/usr/lib/jvm/default-java/lib/server::/home/asaf/miniconda3/envs/dan7/lib/::/home/asaf/miniconda3/envs/dan7/lib/\n",
      "2025-03-10 09:57:03.243815: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import rpy2.robjects as robjects\n",
    "import pandas as pd\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gc\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2515e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 100\n",
    "B = 500\n",
    "n_train = 1000\n",
    "n_val = 200\n",
    "n_test = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08dcb4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>ListVector with 2 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            value\n",
       "            </th>\n",
       "            <td>\n",
       "            <rpy2.rinterface.SexpClosure object at 0x785476d33480> [RTYPES.CLOSXP]\n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            visible\n",
       "            </th>\n",
       "            <td>\n",
       "            <rpy2.rinterface.BoolSexpVector object at 0x785476c04740> [RTYPES.LGLSXP]\n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.ListVector object at 0x785476c17f40> [RTYPES.VECSXP]\n",
       "R classes: ('list',)\n",
       "[SexpClosure, BoolSexpVector]\n",
       "  value: <class 'rpy2.rinterface.SexpClosure'>\n",
       "  <rpy2.rinterface.SexpClosure object at 0x785477c92640> [RTYPES.CLOSXP]\n",
       "  visible: <class 'rpy2.rinterface.BoolSexpVector'>\n",
       "  <rpy2.rinterface.BoolSexpVector object at 0x785476c03b00> [RTYPES.LGLSXP]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_source = robjects.r['source']\n",
    "r_source(\"twoclasssims.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f4f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "simR = robjects.globalenv[\"sim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a6841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(n):\n",
    "    ret = simR(n)\n",
    "    with (robjects.default_converter + pandas2ri.converter).context():\n",
    "        pd_from_r_df = robjects.conversion.get_conversion().rpy2py(ret)\n",
    "    return pd_from_r_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f435d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.415"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sim(1000).Class == \"Class2\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "754fd37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TwoFactor1</th>\n",
       "      <th>TwoFactor2</th>\n",
       "      <th>Linear01</th>\n",
       "      <th>Linear02</th>\n",
       "      <th>Linear03</th>\n",
       "      <th>Linear04</th>\n",
       "      <th>Linear05</th>\n",
       "      <th>Linear06</th>\n",
       "      <th>Linear07</th>\n",
       "      <th>Linear08</th>\n",
       "      <th>Linear09</th>\n",
       "      <th>Linear10</th>\n",
       "      <th>Nonlinear1</th>\n",
       "      <th>Nonlinear2</th>\n",
       "      <th>Nonlinear3</th>\n",
       "      <th>p</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.167583</td>\n",
       "      <td>-0.906375</td>\n",
       "      <td>-0.235831</td>\n",
       "      <td>1.404153</td>\n",
       "      <td>0.720846</td>\n",
       "      <td>0.285401</td>\n",
       "      <td>-0.924058</td>\n",
       "      <td>1.853526</td>\n",
       "      <td>-0.376756</td>\n",
       "      <td>-0.509902</td>\n",
       "      <td>1.197951</td>\n",
       "      <td>0.103598</td>\n",
       "      <td>0.555159</td>\n",
       "      <td>0.012673</td>\n",
       "      <td>0.913378</td>\n",
       "      <td>7.576427e-10</td>\n",
       "      <td>Class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.821312</td>\n",
       "      <td>2.533838</td>\n",
       "      <td>-0.193255</td>\n",
       "      <td>1.201044</td>\n",
       "      <td>1.062711</td>\n",
       "      <td>0.326516</td>\n",
       "      <td>0.986152</td>\n",
       "      <td>0.947547</td>\n",
       "      <td>-0.612700</td>\n",
       "      <td>-0.654574</td>\n",
       "      <td>-0.285227</td>\n",
       "      <td>-0.853064</td>\n",
       "      <td>-0.219745</td>\n",
       "      <td>0.606988</td>\n",
       "      <td>0.994062</td>\n",
       "      <td>9.990737e-01</td>\n",
       "      <td>Class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.181445</td>\n",
       "      <td>0.269797</td>\n",
       "      <td>0.151392</td>\n",
       "      <td>0.372862</td>\n",
       "      <td>0.197272</td>\n",
       "      <td>2.356047</td>\n",
       "      <td>0.065067</td>\n",
       "      <td>0.382931</td>\n",
       "      <td>1.684213</td>\n",
       "      <td>-0.747575</td>\n",
       "      <td>-0.064278</td>\n",
       "      <td>1.090683</td>\n",
       "      <td>-0.094790</td>\n",
       "      <td>0.882775</td>\n",
       "      <td>0.682842</td>\n",
       "      <td>2.286942e-03</td>\n",
       "      <td>Class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.998308</td>\n",
       "      <td>0.721973</td>\n",
       "      <td>-1.429589</td>\n",
       "      <td>-0.125264</td>\n",
       "      <td>-1.013612</td>\n",
       "      <td>-0.048453</td>\n",
       "      <td>-0.756176</td>\n",
       "      <td>0.360564</td>\n",
       "      <td>0.087375</td>\n",
       "      <td>0.738171</td>\n",
       "      <td>1.044010</td>\n",
       "      <td>1.289193</td>\n",
       "      <td>0.452807</td>\n",
       "      <td>0.225105</td>\n",
       "      <td>0.168387</td>\n",
       "      <td>3.415847e-02</td>\n",
       "      <td>Class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.598626</td>\n",
       "      <td>-1.790068</td>\n",
       "      <td>0.925252</td>\n",
       "      <td>-1.042507</td>\n",
       "      <td>-0.275498</td>\n",
       "      <td>0.175261</td>\n",
       "      <td>0.930688</td>\n",
       "      <td>-0.286384</td>\n",
       "      <td>0.480869</td>\n",
       "      <td>-0.386264</td>\n",
       "      <td>-0.588932</td>\n",
       "      <td>-0.356419</td>\n",
       "      <td>0.709397</td>\n",
       "      <td>0.844769</td>\n",
       "      <td>0.775689</td>\n",
       "      <td>2.883260e-01</td>\n",
       "      <td>Class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.482811</td>\n",
       "      <td>0.733282</td>\n",
       "      <td>-0.289784</td>\n",
       "      <td>0.655848</td>\n",
       "      <td>-1.165513</td>\n",
       "      <td>0.768492</td>\n",
       "      <td>-1.000350</td>\n",
       "      <td>-0.274521</td>\n",
       "      <td>1.344269</td>\n",
       "      <td>-0.957317</td>\n",
       "      <td>1.167325</td>\n",
       "      <td>-0.056344</td>\n",
       "      <td>0.278489</td>\n",
       "      <td>0.342425</td>\n",
       "      <td>0.125649</td>\n",
       "      <td>1.462958e-03</td>\n",
       "      <td>Class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.099120</td>\n",
       "      <td>0.338414</td>\n",
       "      <td>0.248076</td>\n",
       "      <td>0.481338</td>\n",
       "      <td>0.863230</td>\n",
       "      <td>-0.454082</td>\n",
       "      <td>-0.119846</td>\n",
       "      <td>-0.925383</td>\n",
       "      <td>-1.093575</td>\n",
       "      <td>-0.545403</td>\n",
       "      <td>-0.201346</td>\n",
       "      <td>0.228146</td>\n",
       "      <td>-0.012224</td>\n",
       "      <td>0.119182</td>\n",
       "      <td>0.148561</td>\n",
       "      <td>4.269457e-03</td>\n",
       "      <td>Class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.255588</td>\n",
       "      <td>1.350561</td>\n",
       "      <td>-0.214890</td>\n",
       "      <td>0.240625</td>\n",
       "      <td>0.957049</td>\n",
       "      <td>-1.645766</td>\n",
       "      <td>-2.202577</td>\n",
       "      <td>-0.787895</td>\n",
       "      <td>0.338652</td>\n",
       "      <td>-1.267944</td>\n",
       "      <td>-0.041282</td>\n",
       "      <td>-0.718327</td>\n",
       "      <td>-0.135028</td>\n",
       "      <td>0.949420</td>\n",
       "      <td>0.667067</td>\n",
       "      <td>9.987892e-01</td>\n",
       "      <td>Class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.266436</td>\n",
       "      <td>-0.050224</td>\n",
       "      <td>0.126693</td>\n",
       "      <td>-0.640259</td>\n",
       "      <td>1.652801</td>\n",
       "      <td>1.085810</td>\n",
       "      <td>-2.367181</td>\n",
       "      <td>0.213665</td>\n",
       "      <td>1.411801</td>\n",
       "      <td>1.327676</td>\n",
       "      <td>0.317156</td>\n",
       "      <td>-0.544926</td>\n",
       "      <td>-0.787141</td>\n",
       "      <td>0.236571</td>\n",
       "      <td>0.244857</td>\n",
       "      <td>8.172659e-03</td>\n",
       "      <td>Class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>-1.064836</td>\n",
       "      <td>-1.519361</td>\n",
       "      <td>-1.018422</td>\n",
       "      <td>-0.925099</td>\n",
       "      <td>-0.432725</td>\n",
       "      <td>0.410248</td>\n",
       "      <td>0.423539</td>\n",
       "      <td>-0.039128</td>\n",
       "      <td>1.391780</td>\n",
       "      <td>-0.613665</td>\n",
       "      <td>-0.264076</td>\n",
       "      <td>1.156908</td>\n",
       "      <td>0.924806</td>\n",
       "      <td>0.423583</td>\n",
       "      <td>0.097524</td>\n",
       "      <td>6.442852e-01</td>\n",
       "      <td>Class2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TwoFactor1  TwoFactor2  Linear01  Linear02  Linear03  Linear04  \\\n",
       "1       1.167583   -0.906375 -0.235831  1.404153  0.720846  0.285401   \n",
       "2       0.821312    2.533838 -0.193255  1.201044  1.062711  0.326516   \n",
       "3       0.181445    0.269797  0.151392  0.372862  0.197272  2.356047   \n",
       "4      -0.998308    0.721973 -1.429589 -0.125264 -1.013612 -0.048453   \n",
       "5      -0.598626   -1.790068  0.925252 -1.042507 -0.275498  0.175261   \n",
       "...          ...         ...       ...       ...       ...       ...   \n",
       "996     0.482811    0.733282 -0.289784  0.655848 -1.165513  0.768492   \n",
       "997     1.099120    0.338414  0.248076  0.481338  0.863230 -0.454082   \n",
       "998    -0.255588    1.350561 -0.214890  0.240625  0.957049 -1.645766   \n",
       "999    -0.266436   -0.050224  0.126693 -0.640259  1.652801  1.085810   \n",
       "1000   -1.064836   -1.519361 -1.018422 -0.925099 -0.432725  0.410248   \n",
       "\n",
       "      Linear05  Linear06  Linear07  Linear08  Linear09  Linear10  Nonlinear1  \\\n",
       "1    -0.924058  1.853526 -0.376756 -0.509902  1.197951  0.103598    0.555159   \n",
       "2     0.986152  0.947547 -0.612700 -0.654574 -0.285227 -0.853064   -0.219745   \n",
       "3     0.065067  0.382931  1.684213 -0.747575 -0.064278  1.090683   -0.094790   \n",
       "4    -0.756176  0.360564  0.087375  0.738171  1.044010  1.289193    0.452807   \n",
       "5     0.930688 -0.286384  0.480869 -0.386264 -0.588932 -0.356419    0.709397   \n",
       "...        ...       ...       ...       ...       ...       ...         ...   \n",
       "996  -1.000350 -0.274521  1.344269 -0.957317  1.167325 -0.056344    0.278489   \n",
       "997  -0.119846 -0.925383 -1.093575 -0.545403 -0.201346  0.228146   -0.012224   \n",
       "998  -2.202577 -0.787895  0.338652 -1.267944 -0.041282 -0.718327   -0.135028   \n",
       "999  -2.367181  0.213665  1.411801  1.327676  0.317156 -0.544926   -0.787141   \n",
       "1000  0.423539 -0.039128  1.391780 -0.613665 -0.264076  1.156908    0.924806   \n",
       "\n",
       "      Nonlinear2  Nonlinear3             p   Class  \n",
       "1       0.012673    0.913378  7.576427e-10  Class1  \n",
       "2       0.606988    0.994062  9.990737e-01  Class2  \n",
       "3       0.882775    0.682842  2.286942e-03  Class1  \n",
       "4       0.225105    0.168387  3.415847e-02  Class1  \n",
       "5       0.844769    0.775689  2.883260e-01  Class2  \n",
       "...          ...         ...           ...     ...  \n",
       "996     0.342425    0.125649  1.462958e-03  Class1  \n",
       "997     0.119182    0.148561  4.269457e-03  Class2  \n",
       "998     0.949420    0.667067  9.987892e-01  Class2  \n",
       "999     0.236571    0.244857  8.172659e-03  Class1  \n",
       "1000    0.423583    0.097524  6.442852e-01  Class2  \n",
       "\n",
       "[1000 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f40fbcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = [\n",
    "    'TwoFactor1',\n",
    "    'TwoFactor2',\n",
    "    'Linear01',\n",
    "    'Linear02',\n",
    "    'Linear03',\n",
    "    'Linear04',\n",
    "    'Linear05',\n",
    "    'Linear06',\n",
    "    'Linear07',\n",
    "    'Linear08',\n",
    "    'Linear09',\n",
    "    'Linear10',\n",
    "    'Nonlinear1',\n",
    "    'Nonlinear2',\n",
    "    'Nonlinear3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25da053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df_train,df_val):\n",
    "    X_train = df_train[fe]\n",
    "    y_train = df_train.Class == \"Class2\"\n",
    "    X_val = df_val[fe]\n",
    "    y_val = df_val.Class == \"Class2\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    #callback = [keras.callbacks.EarlyStopping(monitor='val_loss',patience=1000,restore_best_weights=True)]\n",
    "    callback = [keras.callbacks.EarlyStopping(monitor='val_loss',patience=8,restore_best_weights=True)]\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=500,validation_data=(X_val, y_val),callbacks=callback,verbose=0)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_theta(df_train,df_val,df_test):\n",
    "    res = []\n",
    "    for i in range(M):\n",
    "        model = train_model(df_train,df_val)\n",
    "        ph = model.predict(df_test[fe],verbose=0)\n",
    "        ph = ph.reshape(ph.shape[0])\n",
    "        res += [ph]\n",
    "        del model\n",
    "        keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "    thetha = res[0]\n",
    "    thetha_M = np.stack(res).mean(axis=0)\n",
    "    return thetha,thetha_M,res\n",
    "def get_boot(df_train,df_val,df_test):\n",
    "    res_boot = []\n",
    "    for i in range(B):\n",
    "        df_train_boot = df_train.sample(n=df_train.shape[0],replace=True)\n",
    "        df_val_boot = df_val.sample(n=df_val.shape[0],replace=True)\n",
    "        #df_val = sim(n_val)\n",
    "        model = train_model(df_train_boot,df_val_boot)\n",
    "        ph = model.predict(df_test[fe],verbose=0)\n",
    "        ph = ph.reshape(ph.shape[0])\n",
    "        res_boot += [ph]\n",
    "        del model\n",
    "        keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "    res_boot = np.stack(res_boot)\n",
    "    return res_boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41d317d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 09:57:04.049472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-10 09:57:04.053082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-10 09:57:04.053184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-10 09:57:04.053631: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-10 09:57:04.054640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-10 09:57:04.054752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-10 09:57:04.054821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-10 09:57:04.358814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-10 09:57:04.359032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-10 09:57:04.359109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-10 09:57:04.359178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-03-10 09:57:05.068904: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "df_test = sim(n_test)\n",
    "thetha_arr = []\n",
    "res_boot_arr = []\n",
    "k=100\n",
    "for i in range(k):\n",
    "    print(i)\n",
    "    df_train = sim(n_train)\n",
    "    df_val = sim(n_val)\n",
    "    thetha_arr += [get_theta(df_train,df_val,df_test)]\n",
    "    res_boot_arr += [get_boot(df_train,df_val,df_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "686cd267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8740000000000004 0.8570444252754446 0.8909555747245563 0.16312386958299335\n"
     ]
    }
   ],
   "source": [
    "res = 0\n",
    "res_width = 0\n",
    "res_all = []\n",
    "for i in range(k):\n",
    "    thetha, thetha_M,rr = thetha_arr[i]\n",
    "    res_boot = res_boot_arr[i]\n",
    "    delta = np.percentile(np.abs(res_boot - thetha_M),90,axis=0)\n",
    "    tmp = ((df_test.p > thetha - delta) & (df_test.p < thetha + delta)).mean()\n",
    "    res += tmp\n",
    "    res_all += [tmp]\n",
    "    res_width  += delta.mean()\n",
    "\n",
    "bw = (1.96*np.array(res_all).std()/10)\n",
    "print(res/k,res/k - bw, res/k + bw,res_width/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "115f1743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9533899999999995 0.9503457603303282 0.9564342396696708 0.19204022825196773\n"
     ]
    }
   ],
   "source": [
    "res = 0\n",
    "res_width = 0\n",
    "res_all = []\n",
    "for i in range(k):\n",
    "    thetha, thetha_M,rr = thetha_arr[i]\n",
    "    res_boot = res_boot_arr[i]\n",
    "    delta = np.percentile(np.abs(res_boot - thetha),90,axis=0)\n",
    "    tmp = ((df_test.p > thetha - delta) & (df_test.p < thetha + delta)).mean()\n",
    "    res += tmp\n",
    "    res_all += [tmp]\n",
    "    res_width  += delta.mean()\n",
    "\n",
    "bw = (1.96*np.array(res_all).std()/10)\n",
    "print(res/k,res/k - bw, res/k + bw,res_width/k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
