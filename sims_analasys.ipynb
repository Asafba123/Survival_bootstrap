{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3c01a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from boot_util import *\n",
    "import os\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4028be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_out_dir_path(conf):\n",
    "    return f\"{conf['out_dir']}/{conf['sample_type']}_n_{conf['n_train']}_p_{conf['patience']}_s_{conf['seed']}_c_{conf['control']}_p_{conf['m']}_d_{conf['depth']}_w_{conf['layer_size']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b06750aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "confs_path = [\"conf_1.json\",\"conf_2.json\",\"conf_4.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57b34dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_log(S):\n",
    "    #return np.log(1-S)\n",
    "    S = np.clip(S,0,1)\n",
    "    return np.arcsin((1-S)**0.5)\n",
    "\n",
    "def inverse_transform_log(U):\n",
    "    U = np.clip(U,0,transform_log(0))\n",
    "    #return -1*(np.exp(U)) + 1\n",
    "    return -1*(np.sin(-1*U)**2) + 1\n",
    "    #return np.sin(U)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "47de7988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "save_d_95 = []\n",
    "save_d_90 = []\n",
    "save_d_95_naive = []\n",
    "save_d_90_naive = []\n",
    "anls = []\n",
    "for conf_path in confs_path:\n",
    "    confs = json.load(open(conf_path,\"r\"))\n",
    "    for conf in confs:\n",
    "        bdir = get_out_dir_path(conf)\n",
    "        if conf[\"sample_type\"] == \"LPH\":\n",
    "            sm = SimStudyLinearPH()\n",
    "        elif conf[\"sample_type\"] == \"NLPH\":\n",
    "            sm = SimStudyNonLinearPH()\n",
    "        elif conf[\"sample_type\"] == \"NLNPH\":\n",
    "            sm = SimStudyNonLinearNonPH_smooth()\n",
    "        elif conf[\"sample_type\"] == \"Deep1\":\n",
    "            sm = SimStudyDeep1()\n",
    "        elif conf[\"sample_type\"] == \"Deep2\":\n",
    "            sm = SimStudyDeep2()\n",
    "        else:\n",
    "            raise Exception(\"Unkowne sample method\")\n",
    "        if \"analasys_offset\" in conf.keys():\n",
    "            offset_start,offset_end = conf[\"analasys_offset\"]\n",
    "        preds_all = pd.read_csv(f\"{bdir}/res_boot_samp_0_boot_0.csv\",compression=\"gzip\") \n",
    "        preds_all = preds_all.drop(list(preds_all)[0],axis=1).set_index(\"t\").drop(0.0)\n",
    "        df_test = pd.read_csv(f\"{bdir}/test.csv\",compression=\"gzip\")\n",
    "\n",
    "        grid_start, grid_end, grid_step = conf[\"grid\"]\n",
    "        grid = np.arange(grid_start,grid_end,grid_step)[1:]\n",
    "        x = np.array(df_test[conf[\"cols_leave\"]])\n",
    "        df_test = pd.DataFrame([np.exp(-1*sm.cum_hazard(t,x)) for t in grid]).set_index(preds_all.index)\n",
    "\n",
    "        if \"analasys_offset\" in conf.keys():\n",
    "            df_test =df_test.iloc[offset_start:offset_end]\n",
    "        \n",
    "        count_90 = np.zeros(df_test.shape[1])\n",
    "        count_95 = np.zeros(df_test.shape[1])\n",
    "        \n",
    "        count_90_W = np.zeros(df_test.shape[1])\n",
    "        count_95_W = np.zeros(df_test.shape[1])\n",
    "\n",
    "        count_90_naive = np.zeros(df_test.shape[1])\n",
    "        count_95_naive = np.zeros(df_test.shape[1])\n",
    "        thetha_bias = 0\n",
    "        m_bias = 0\n",
    "        avg_bw_len_90 = 0\n",
    "        avg_bw_len_95 = 0\n",
    "\n",
    "        avg_bw_len_90_naive = 0\n",
    "        avg_bw_len_95_naive = 0\n",
    "        \n",
    "        avg_bw_len_90_W = 0\n",
    "        avg_bw_len_95_W = 0\n",
    "        for j in range(conf[\"n_samp\"]):\n",
    "            print(j)\n",
    "            preds_all = pd.read_csv(f\"{bdir}/res_boot_samp_{j}_boot_0.csv\",compression=\"gzip\") \n",
    "            preds_all = preds_all.drop(list(preds_all)[0],axis=1).set_index(\"t\").drop(0.0)\n",
    "            if \"analasys_offset\" in conf.keys():\n",
    "                preds_all = preds_all.iloc[offset_start:offset_end]\n",
    "            \n",
    "            thetha = pd.read_csv(f\"{bdir}/theta_{j}.csv\",compression=\"gzip\") \n",
    "            thetha = thetha.drop(list(thetha)[0],axis=1).set_index(\"t\").drop(0.0)        \n",
    "            if \"analasys_offset\" in conf.keys():\n",
    "                thetha = thetha.iloc[offset_start:offset_end]\n",
    "            \n",
    "            distances = []\n",
    "            distances_naive = []\n",
    "            distances_by_t = []\n",
    "            distances_W = []\n",
    "            for i in range(1,conf[\"n_boot\"]):\n",
    "                preds_boot = pd.read_csv(f\"{bdir}/res_boot_samp_{j}_boot_{i}.csv\",compression=\"gzip\") \n",
    "                preds_boot = preds_boot.drop(list(preds_boot)[0],axis=1).set_index(\"t\").drop(0.0)\n",
    "                if \"analasys_offset\" in conf.keys():\n",
    "                    preds_boot = preds_boot.iloc[offset_start:offset_end]\n",
    "                \n",
    "                distances += [pd.DataFrame(np.array(preds_boot) - np.array(preds_all)).abs().max(axis=0)]\n",
    "                distances_by_t += [pd.DataFrame(np.array(preds_boot) - np.array(preds_all))]\n",
    "                distances_naive += [pd.DataFrame(np.array(preds_boot) - np.array(thetha)).abs().max(axis=0)]\n",
    "                #distances_W += [((transform_log(preds_boot) - transform_log(preds_all))).abs().max(axis=0)]\n",
    "                clp = np.clip(preds_boot,0.01,0.99)\n",
    "                W = (clp*(1-clp))**0.5\n",
    "                distances_W += [((preds_boot - preds_all)/W).abs().max(axis=0)]\n",
    "            bias = []\n",
    "            for pos in range(df_test.shape[1]):\n",
    "                aa = np.stack([x[pos] for x in distances_by_t])\n",
    "                bias += [aa.mean(axis=0)]\n",
    "            bias = np.stack(bias)\n",
    "            distances = pd.concat(distances,axis=1)\n",
    "            distances_naive = pd.concat(distances_naive,axis=1)\n",
    "            d_90 = np.percentile(distances,90,axis=1)\n",
    "            d_90_naive = np.percentile(distances_naive,90,axis=1)\n",
    "            d_95 = np.percentile(distances,95,axis=1)\n",
    "            d_95_naive = np.percentile(distances_naive,95,axis=1)\n",
    "            distances_W = pd.concat(distances_W,axis=1)\n",
    "            d_95_W = np.percentile(distances_W,95,axis=1)\n",
    "            d_90_W = np.percentile(distances_W,90,axis=1)\n",
    "\n",
    "            save_d_95 += [d_95]\n",
    "            save_d_90 += [d_90]\n",
    "            save_d_95_naive += [d_95_naive]\n",
    "            save_d_90_naive += [d_90_naive]\n",
    "            l = 0\n",
    "            for idx, row in df_test.T.iterrows():\n",
    "                res_real = np.array(row)\n",
    "                res_all = thetha[str(idx)]\n",
    "                m_all = preds_all[str(idx)]\n",
    "                bw_90 = d_90[l]\n",
    "                bw_90_naive = d_90_naive[l]\n",
    "                bw_95 = d_95[l]\n",
    "                bw_95_naive = d_95_naive[l]\n",
    "\n",
    "                bias_i = bias[l,:] \n",
    "\n",
    "                in_bw_90 = ((res_real > (res_all + bw_90)).sum() + (res_real < (res_all - bw_90)).sum() > 0)\n",
    "                in_bw_95 = ((res_real > (res_all + bw_95)).sum() + (res_real < (res_all - bw_95)).sum() > 0)\n",
    "                count_90[l] += in_bw_90\n",
    "                count_95[l] += in_bw_95\n",
    "                \n",
    "                \n",
    "                clp = np.clip(res_all,0.01,0.99)\n",
    "                W = (clp*(1-clp))**0.5\n",
    "                \n",
    "                \n",
    "                bw_W = d_90_W[l]\n",
    "                in_bw_90_W = ((res_real > (res_all + bw_W*W)).sum() + (res_real < (res_all - bw_W*W)).sum() > 0)\n",
    "                avg_bw_len_90_W += bw_W*W.mean()\n",
    "                \n",
    "                bw_W = d_95_W[l]\n",
    "                in_bw_95_W = ((res_real > (res_all + bw_W*W)).sum() + (res_real < (res_all - bw_W*W)).sum() > 0)\n",
    "                avg_bw_len_95_W += bw_W*W.mean()\n",
    "                #in_bw_90_W = ((res_real < ((inverse_transform_log(transform_log(res_all) + d_90_W[i])))).sum() + (res_real > ((inverse_transform_log(transform_log(res_all) - d_90_W[i])))).sum() > 0)\n",
    "                #in_bw_95_W = ((res_real < ((inverse_transform_log(transform_log(res_all) + d_95_W[i])))).sum() + (res_real > ((inverse_transform_log(transform_log(res_all) - d_95_W[i])))).sum() > 0)\n",
    "                count_90_W[l] += in_bw_90_W\n",
    "                count_95_W[l] += in_bw_95_W\n",
    "\n",
    "                in_bw_90_naive = ((res_real > (res_all + bw_90_naive)).sum() + (res_real < (res_all - bw_90_naive)).sum() > 0)\n",
    "                in_bw_95_naive = ((res_real > (res_all + bw_95_naive)).sum() + (res_real < (res_all - bw_95_naive)).sum() > 0)\n",
    "                count_90_naive[l] += in_bw_90_naive\n",
    "                count_95_naive[l] += in_bw_95_naive\n",
    "                \n",
    "                #avg_bw_len_90_W += np.abs(inverse_transform_log(transform_log(res_real) + d_90_W[i]) - inverse_transform_log(transform_log(res_real) - d_90_W[i])).mean()\n",
    "                #avg_bw_len_95_W += np.abs(inverse_transform_log(transform_log(res_real) + d_95_W[i]) - inverse_transform_log(transform_log(res_real) - d_95_W[i])).mean()\n",
    "\n",
    "                \n",
    "                thetha_bias += (res_real - res_all).abs().max()\n",
    "                m_bias += (res_real - m_all).abs().max()\n",
    "                avg_bw_len_90 += bw_90\n",
    "                avg_bw_len_95 += bw_95\n",
    "\n",
    "                avg_bw_len_90_naive += bw_90_naive\n",
    "                avg_bw_len_95_naive += bw_95_naive\n",
    "                l+=1\n",
    "                \n",
    "\n",
    "\n",
    "        anls += [\n",
    "            {\n",
    "            \"bdir\" : bdir,\n",
    "            \"cover_90\" : (1 - (count_90/conf[\"n_samp\"]).mean()),\n",
    "            \"cover_95\" : (1 - (count_95/conf[\"n_samp\"]).mean()),\n",
    "            \"cover_90_W\" : (1 - (count_90_W/conf[\"n_samp\"]).mean()),\n",
    "            \"cover_95_W\" : (1 - (count_95_W/conf[\"n_samp\"]).mean()),\n",
    "            \"cover_90_naive\" : (1 - (count_90_naive/conf[\"n_samp\"]).mean()),\n",
    "            \"cover_95_naive\" : (1 - (count_95_naive/conf[\"n_samp\"]).mean()),\n",
    "            \"bias_thetha\" : thetha_bias /(conf[\"n_samp\"]*df_test.shape[1]),\n",
    "            \"bias_m\" : m_bias /(conf[\"n_samp\"]*df_test.shape[1]),\n",
    "            \"bw_90\" : avg_bw_len_90 /(conf[\"n_samp\"]*df_test.shape[1]),\n",
    "            \"bw_95\" : avg_bw_len_95 /(conf[\"n_samp\"]*df_test.shape[1]),\n",
    "            \"bw_90_W\" : avg_bw_len_90_W /(conf[\"n_samp\"]*df_test.shape[1]),\n",
    "            \"bw_95_W\" : avg_bw_len_95_W /(conf[\"n_samp\"]*df_test.shape[1]),\n",
    "            \"bw_90_naive\" : avg_bw_len_90_naive /(conf[\"n_samp\"]*df_test.shape[1]),\n",
    "            \"bw_95_naive\" : avg_bw_len_95_naive /(conf[\"n_samp\"]*df_test.shape[1]),\n",
    "            }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0fdcb72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bdir</th>\n",
       "      <th>cover_90</th>\n",
       "      <th>cover_95</th>\n",
       "      <th>cover_90_W</th>\n",
       "      <th>cover_95_W</th>\n",
       "      <th>cover_90_naive</th>\n",
       "      <th>cover_95_naive</th>\n",
       "      <th>bias_thetha</th>\n",
       "      <th>bias_m</th>\n",
       "      <th>bw_90</th>\n",
       "      <th>bw_95</th>\n",
       "      <th>bw_90_W</th>\n",
       "      <th>bw_95_W</th>\n",
       "      <th>bw_90_naive</th>\n",
       "      <th>bw_95_naive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../sims//NLNPH_n_10000_p_25_s_1_c_1_p_100_d_6_...</td>\n",
       "      <td>0.90316</td>\n",
       "      <td>0.95102</td>\n",
       "      <td>0.88137</td>\n",
       "      <td>0.93262</td>\n",
       "      <td>0.98937</td>\n",
       "      <td>0.99692</td>\n",
       "      <td>0.075976</td>\n",
       "      <td>0.049317</td>\n",
       "      <td>0.130058</td>\n",
       "      <td>0.151398</td>\n",
       "      <td>0.091193</td>\n",
       "      <td>0.108586</td>\n",
       "      <td>0.157855</td>\n",
       "      <td>0.180131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../sims//NLNPH_n_10000_p_25_s_1_c_2_p_100_d_6_...</td>\n",
       "      <td>0.89062</td>\n",
       "      <td>0.94381</td>\n",
       "      <td>0.87092</td>\n",
       "      <td>0.92696</td>\n",
       "      <td>0.98508</td>\n",
       "      <td>0.99591</td>\n",
       "      <td>0.071182</td>\n",
       "      <td>0.048053</td>\n",
       "      <td>0.118033</td>\n",
       "      <td>0.137068</td>\n",
       "      <td>0.082655</td>\n",
       "      <td>0.097348</td>\n",
       "      <td>0.142785</td>\n",
       "      <td>0.162860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../sims//NLNPH_n_10000_p_25_s_1_c_4_p_100_d_6_...</td>\n",
       "      <td>0.89233</td>\n",
       "      <td>0.94460</td>\n",
       "      <td>0.87403</td>\n",
       "      <td>0.93126</td>\n",
       "      <td>0.97810</td>\n",
       "      <td>0.99305</td>\n",
       "      <td>0.066654</td>\n",
       "      <td>0.047628</td>\n",
       "      <td>0.110030</td>\n",
       "      <td>0.127595</td>\n",
       "      <td>0.077125</td>\n",
       "      <td>0.090207</td>\n",
       "      <td>0.131316</td>\n",
       "      <td>0.149804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                bdir  cover_90  cover_95  \\\n",
       "0  ../sims//NLNPH_n_10000_p_25_s_1_c_1_p_100_d_6_...   0.90316   0.95102   \n",
       "1  ../sims//NLNPH_n_10000_p_25_s_1_c_2_p_100_d_6_...   0.89062   0.94381   \n",
       "2  ../sims//NLNPH_n_10000_p_25_s_1_c_4_p_100_d_6_...   0.89233   0.94460   \n",
       "\n",
       "   cover_90_W  cover_95_W  cover_90_naive  cover_95_naive  bias_thetha  \\\n",
       "0     0.88137     0.93262         0.98937         0.99692     0.075976   \n",
       "1     0.87092     0.92696         0.98508         0.99591     0.071182   \n",
       "2     0.87403     0.93126         0.97810         0.99305     0.066654   \n",
       "\n",
       "     bias_m     bw_90     bw_95   bw_90_W   bw_95_W  bw_90_naive  bw_95_naive  \n",
       "0  0.049317  0.130058  0.151398  0.091193  0.108586     0.157855     0.180131  \n",
       "1  0.048053  0.118033  0.137068  0.082655  0.097348     0.142785     0.162860  \n",
       "2  0.047628  0.110030  0.127595  0.077125  0.090207     0.131316     0.149804  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(anls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d2035880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../sims//NLNPH_n_10000_p_25_s_1_c_1_p_100_d_6_w_128 ---- & 0.989 & 0.158 & 0.997 & 0.180 & 0.076 & 0.049 & 0.903 & 0.130 & 0.951 & 0.151 & 0.881 & 0.091 & 0.933 & 0.109\n",
      "../sims//NLNPH_n_10000_p_25_s_1_c_2_p_100_d_6_w_128 ---- & 0.985 & 0.143 & 0.996 & 0.163 & 0.071 & 0.048 & 0.891 & 0.118 & 0.944 & 0.137 & 0.871 & 0.083 & 0.927 & 0.097\n",
      "../sims//NLNPH_n_10000_p_25_s_1_c_4_p_100_d_6_w_128 ---- & 0.978 & 0.131 & 0.993 & 0.150 & 0.067 & 0.048 & 0.892 & 0.110 & 0.945 & 0.128 & 0.874 & 0.077 & 0.931 & 0.090\n"
     ]
    }
   ],
   "source": [
    "for _,row in pd.DataFrame(anls).iterrows():\n",
    "    print(f\"{row.bdir} ---- & {row.cover_90_naive:.3f} & {row.bw_90_naive:.3f} & {row.cover_95_naive:.3f} & {row.bw_95_naive:.3f} & {row.bias_thetha:.3f} & {row.bias_m:.3f} & {row.cover_90:.3f} & {row.bw_90:.3f} & {row.cover_95:.3f} & {row.bw_95:.3f} & {row.cover_90_W:.3f} & {row.bw_90_W:.3f} & {row.cover_95_W:.3f} & {row.bw_95_W:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
